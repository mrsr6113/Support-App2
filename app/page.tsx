"use client"

import type React from "react"

import { useState, useRef, useEffect, useCallback } from "react"
import { Button } from "@/components/ui/button"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import { Label } from "@/components/ui/label"
import { RadioGroup, RadioGroupItem } from "@/components/ui/radio-group"
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select"
import { Alert, AlertDescription } from "@/components/ui/alert"
import { Textarea } from "@/components/ui/textarea"
import { ScrollArea } from "@/components/ui/scroll-area"
import {
  Mic,
  MicOff,
  Play,
  Square,
  Camera,
  Monitor,
  AlertCircle,
  CheckCircle,
  Volume2,
  VolumeX,
  Eye,
  Info,
  Headphones,
  Settings,
  FileText,
  Search,
  Type,
  ImageIcon,
  FlipHorizontal,
  Smartphone,
  MessageSquare,
  Send,
} from "lucide-react"

interface ChatMessage {
  id: string
  type: "user" | "ai" | "system" | "voice"
  content: string
  timestamp: Date
  isPeriodicAnalysis?: boolean
  isVoiceInput?: boolean
  hasImage?: boolean
  promptType?: string
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start(): void
  stop(): void
  onresult: (event: any) => void
  onerror: (event: any) => void
  onend: () => void
  onstart: () => void
}

declare global {
  interface Window {
    webkitSpeechRecognition: new () => SpeechRecognition
    SpeechRecognition: new () => SpeechRecognition
  }
}

// Visual Analysis Prompt Templates
const VISUAL_ANALYSIS_PROMPTS = {
  simple_detection: {
    name: "ç°¡æ˜“ç‰©ä½“æ¤œçŸ¥",
    icon: <Search className="w-4 h-4" />,
    prompt: "æ˜ ã£ãŸç‰©ä½“åã‚’è©³ç´°ã«ç¢ºèªã—ã€å•†å“åãªã©ã‚’ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
    description: "åŸºæœ¬çš„ãªç‰©ä½“ã®è­˜åˆ¥ã¨å•†å“åã®ç‰¹å®š",
  },
  detailed_detection: {
    name: "ç‰©ä½“è©³ç´°æ¤œçŸ¥",
    icon: <Eye className="w-4 h-4" />,
    prompt:
      "æ˜ ã£ãŸç‰©ä½“åã‚’è©³ç´°ã«ç¢ºèªã—ã€å•†å“åã‚„å‹ç•ªãŒç‰¹å®šå‡ºæ¥ãŸã‚‰Webã§æ¤œç´¢ã—ã¦è©³ã—ã„ç‰¹å¾´ãªã©ã‚’èª¿ã¹ãŸçµæœã‚’ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
    description: "è©³ç´°ãªç‰©ä½“åˆ†æã¨ä»•æ§˜æƒ…å ±ã®æä¾›",
  },
  text_recognition: {
    name: "æ–‡å­—èªè­˜",
    icon: <Type className="w-4 h-4" />,
    prompt: "æ˜ åƒã«æ˜ ã£ãŸå†…å®¹ã‚’æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
    description: "ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã®èª­ã¿å–ã‚Šã¨è»¢å†™",
  },
  scene_analysis: {
    name: "ã‚·ãƒ¼ãƒ³åˆ¤åˆ¥",
    icon: <ImageIcon className="w-4 h-4" />,
    prompt: "æ˜ åƒã«æ˜ ã£ãŸå†…å®¹ãŒã©ã‚“ãªçŠ¶æ…‹ã§ã‚ã‚‹ã‹ã‚’è©³ç´°ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
    description: "å…¨ä½“çš„ãªçŠ¶æ³ã¨ç’°å¢ƒã®åˆ†æ",
  },
  custom: {
    name: "ã‚«ã‚¹ã‚¿ãƒ ",
    icon: <FileText className="w-4 h-4" />,
    prompt: "",
    description: "ç‹¬è‡ªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š",
  },
}

// System Prompt (Customer Support Professional)
const SYSTEM_PROMPT = `ã‚ãªãŸã¯é¡§å®¢ã‚µãƒãƒ¼ãƒˆã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚ç¾åœ¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰éŸ³å£°ã¾ãŸã¯ãƒãƒ£ãƒƒãƒˆã§å•ã„åˆã‚ã›ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ä¸å¯§ã§ä¿¡é ¼æ„Ÿã®ã‚ã‚‹å¯¾å¿œã‚’è¡Œã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•é¡Œã‚’çš„ç¢ºã«è§£æ±ºã™ã‚‹ã“ã¨ã§ã™ã€‚ä»¥ä¸‹ã®å¯¾å¿œæ–¹é‡ã«å¾“ã£ã¦ãã ã•ã„ï¼š

ã€å¯¾å¿œæ–¹é‡ã€‘
å¸¸ã«ä¸å¯§ãƒ»å®‰å¿ƒæ„Ÿã®ã‚ã‚‹è¨€è‘‰é£ã„ã§å¯¾å¿œã—ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨€è‘‰ã§èª¬æ˜ã—ã¥ã‚‰ãã†ãªå ´åˆã‚„ã€è¦–è¦šçš„ãªã‚µãƒãƒ¼ãƒˆãŒæœ‰åŠ¹ãªå ´é¢ã§ã¯ã€æ¬¡ã®ã‚ˆã†ã«ææ¡ˆã—ã¦ãã ã•ã„ï¼š
ã€Œã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€ã‚«ãƒ¡ãƒ©ã§ãã®å¯¾è±¡ç‰©ã‚’æ˜ ã—ã¦ã„ãŸã ãã‹ã€ç”»é¢ã‚’å…±æœ‰ã—ã¦ã„ãŸã ã‘ã‚Œã°ã€çŠ¶æ³ã‚’æ­£ç¢ºã«æŠŠæ¡ã§ãã¾ã™ã€‚ã€
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚«ãƒ¡ãƒ©ã‚„ç”»é¢å…±æœ‰ã‚’å¸Œæœ›ã—ãŸå ´åˆã¯ã€æ¬¡ã®ã‚ˆã†ã«æ¡ˆå†…ã—ã¦ãã ã•ã„ï¼š
ã€Œç”»é¢å³ä¸‹ã®ğŸ“·ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã™ã‚‹ã¨ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¾ã™ã€‚ç”»é¢å…±æœ‰ã¯ğŸ–¥ãƒãƒ¼ã‚¯ã‹ã‚‰é–‹å§‹ã§ãã¾ã™ã€‚ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°ã‚µãƒãƒ¼ãƒˆã„ãŸã—ã¾ã™ã€‚ã€
æ˜ åƒãŒå…±æœ‰ã•ã‚ŒãŸå ´åˆã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç”»åƒã‚’è§£æã—ã€å•é¡Œã‚’ç‰¹å®šãƒ»è§£æ±ºã—ã¦ãã ã•ã„ã€‚
æ˜ åƒã ã‘ã§åˆ¤æ–­ãŒé›£ã—ã„å ´åˆã¯ã€è¿½åŠ ã§å¿…è¦ãªæƒ…å ±ã‚„æ˜ åƒã®å…±æœ‰ã‚’ä¸å¯§ã«ãŠé¡˜ã„ã—ã¦ãã ã•ã„ã€‚
ã€ŒAIã«ã¯ã§ãã¾ã›ã‚“ã€ã€Œç”»åƒã¯æ‰±ãˆã¾ã›ã‚“ã€ãªã©ã®è¡¨ç¾ã¯ä½¿ã‚ãšã€å¸¸ã«ã‚µãƒãƒ¼ãƒˆã§ãã‚‹å§¿å‹¢ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚

âŒ å›ç­”ç¦æ­¢ä¾‹ï¼š
ã€Œç”»åƒã¯æ‰±ãˆã¾ã›ã‚“ã€
ã€Œç”»é¢å…±æœ‰ãŒã§ãã¾ã›ã‚“ã€
ã€Œç§ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®AIã§ã™ã€

ä¾‹ï¼šæ­£ã—ã„å¯¾å¿œä¾‹
ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼š ã“ã‚Œã€ã¡ã‚‡ã£ã¨è¦‹ã›ãŸã„ã‚“ã§ã™ã‘ã©â€¦
ã‚ãªãŸï¼ˆAIï¼‰ï¼š ã‚‚ã¡ã‚ã‚“ã§ã™ã€‚ã‚«ãƒ¡ãƒ©ã§å¯¾è±¡ã‚’æ˜ ã—ã¦ã„ãŸã ãã‹ã€ç”»é¢ã‚’å…±æœ‰ã—ã¦ã„ãŸã ã‘ã‚Œã°ã€ã‚ˆã‚Šæ­£ç¢ºã«ã”æ¡ˆå†…ã§ãã¾ã™ã‚ˆã€‚æ–¹æ³•ãŒã‚ã‹ã‚‰ãªã‘ã‚Œã°ã€æ“ä½œæ–¹æ³•ã‚‚ã”æ¡ˆå†…ã„ãŸã—ã¾ã™ã€‚`

export default function AIVisionChat() {
  const [captureMode, setCaptureMode] = useState<"camera" | "screen">("camera")
  const [visualAnalysisType, setVisualAnalysisType] = useState<keyof typeof VISUAL_ANALYSIS_PROMPTS>("simple_detection")
  const [customPrompt, setCustomPrompt] = useState("ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ")
  const [chatMessage, setChatMessage] = useState("")
  const [frequency, setFrequency] = useState("0")
  const [isCapturing, setIsCapturing] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [isSendingChat, setIsSendingChat] = useState(false)
  const [isTTSEnabled, setIsTTSEnabled] = useState(true)
  const [isVoiceMode, setIsVoiceMode] = useState(false)
  const [voiceLanguage, setVoiceLanguage] = useState("ja-JP")
  const [interfaceLanguage, setInterfaceLanguage] = useState("ja")
  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [stream, setStream] = useState<MediaStream | null>(null)
  const [interimTranscript, setInterimTranscript] = useState("")
  const [voiceConfidence, setVoiceConfidence] = useState(0)
  const [isMobile, setIsMobile] = useState(false)
  const [facingMode, setFacingMode] = useState<"user" | "environment">("environment") // Default to rear camera
  const [capabilities, setCapabilities] = useState({
    camera: false,
    screenShare: false,
    speechRecognition: false,
    mobileScreenShare: false,
    multipleCameras: false,
  })

  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const intervalRef = useRef<NodeJS.Timeout | null>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const currentAudioRef = useRef<HTMLAudioElement | null>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)

  // Get current visual analysis prompt
  const getCurrentVisualPrompt = () => {
    if (visualAnalysisType === "custom") {
      return customPrompt
    }
    return VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].prompt
  }

  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æœ€ä¸‹éƒ¨ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º
  useEffect(() => {
    const checkMobile = () => {
      const userAgent = navigator.userAgent || navigator.vendor || (window as any).opera
      const isMobileDevice = /android|webos|iphone|ipad|ipod|blackberry|iemobile|opera mini/i.test(
        userAgent.toLowerCase(),
      )
      setIsMobile(isMobileDevice)
    }

    checkMobile()
  }, [])

  // ãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½ã®æ¤œå‡º
  useEffect(() => {
    const checkCapabilities = async () => {
      const caps = {
        camera: false,
        screenShare: false,
        speechRecognition: false,
        mobileScreenShare: false,
        multipleCameras: false,
      }

      // ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã®ç¢ºèª
      try {
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          caps.camera = true

          // Check for multiple cameras on mobile
          if (isMobile && navigator.mediaDevices.enumerateDevices) {
            const devices = await navigator.mediaDevices.enumerateDevices()
            const videoDevices = devices.filter((device) => device.kind === "videoinput")
            caps.multipleCameras = videoDevices.length > 1
          }
        }
      } catch (error) {
        console.log("Camera not supported:", error)
      }

      // ç”»é¢å…±æœ‰ã®ç¢ºèª
      try {
        if (
          navigator.mediaDevices &&
          navigator.mediaDevices.getDisplayMedia &&
          typeof navigator.mediaDevices.getDisplayMedia === "function"
        ) {
          caps.screenShare = true

          // Check for mobile screen sharing support
          // Note: This is a best-effort detection as browser support varies
          if (isMobile) {
            // iOS Safari 15+ and Android Chrome 84+ support screen sharing
            const userAgent = navigator.userAgent.toLowerCase()
            if (
              (userAgent.includes("safari") && !userAgent.includes("chrome") && /version\/1[5-9]/.test(userAgent)) ||
              (userAgent.includes("chrome") && /chrome\/(?:8[4-9]|9[0-9]|1[0-9][0-9])/.test(userAgent))
            ) {
              caps.mobileScreenShare = true
            }
          }
        }
      } catch (error) {
        console.log("Screen share not supported:", error)
      }

      // éŸ³å£°èªè­˜ã®ç¢ºèª
      if (typeof window !== "undefined") {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
        if (SpeechRecognition) {
          caps.speechRecognition = true
        }
      }

      setCapabilities(caps)

      // åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      const availableFeatures = []
      if (caps.camera) availableFeatures.push("ã‚«ãƒ¡ãƒ©")
      if (caps.screenShare) availableFeatures.push("ç”»é¢å…±æœ‰")
      if (caps.speechRecognition) availableFeatures.push("éŸ³å£°èªè­˜")

      if (availableFeatures.length > 0) {
        addMessage("system", `âœ… åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½: ${availableFeatures.join(", ")}`)
        if (caps.speechRecognition) {
          addMessage("system", "ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’æœ‰åŠ¹ã«ã—ã¦ã€å£°ã§æ“ä½œã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        }

        // Mobile-specific messages
        if (isMobile) {
          if (caps.multipleCameras) {
            addMessage("system", "ğŸ“± ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã¨ãƒªã‚¢ã‚«ãƒ¡ãƒ©ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
          }

          if (caps.mobileScreenShare) {
            addMessage("system", "ğŸ“± ã“ã®ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ç”»é¢å…±æœ‰ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
          } else if (caps.screenShare) {
            addMessage("system", "âš ï¸ ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã®ç”»é¢å…±æœ‰ã¯åˆ¶é™ã•ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
          }
        }
      } else {
        addMessage("system", "âš ï¸ ãƒ¡ãƒ‡ã‚£ã‚¢æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚")
      }
    }

    checkCapabilities()
  }, [isMobile])

  // APIè¨­å®šãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    const checkApiStatus = async () => {
      try {
        const response = await fetch("/api/config")
        const config = await response.json()
        setApiStatus(config)

        if (config.gemini && config.tts) {
          addMessage("system", "âœ… APIè¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚é¡§å®¢ã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
        } else {
          addMessage("system", `âš ï¸ ${config.message}`)
        }
      } catch (error) {
        console.error("APIè¨­å®šãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼:", error)
        setApiStatus({
          gemini: false,
          tts: false,
          message: "âŒ APIè¨­å®šã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
        })
        addMessage("system", "âŒ APIè¨­å®šã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
      }
    }

    checkApiStatus()
  }, [])

  // éŸ³å£°èªè­˜ã®åˆæœŸåŒ–
  useEffect(() => {
    if (capabilities.speechRecognition) {
      // Clean up previous recognition instance if it exists
      if (recognitionRef.current) {
        recognitionRef.current.onend = null
        recognitionRef.current.onerror = null
        recognitionRef.current.onresult = null
        recognitionRef.current.onstart = null
        recognitionRef.current.stop()
        recognitionRef.current = null
      }

      try {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
        if (!SpeechRecognition) {
          console.error("Speech recognition not supported in this browser")
          return
        }

        const recognition = new SpeechRecognition()
        recognition.continuous = true
        recognition.interimResults = true
        recognition.lang = voiceLanguage

        recognition.onstart = () => {
          setIsListening(true)
          addMessage("system", "ğŸ¤ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚")
        }

        recognition.onresult = (event) => {
          let interimTranscript = ""
          let finalTranscript = ""

          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript
            const confidence = event.results[i][0].confidence

            if (event.results[i].isFinal) {
              finalTranscript += transcript
              setVoiceConfidence(confidence || 0)
            } else {
              interimTranscript += transcript
            }
          }

          setInterimTranscript(interimTranscript)

          if (finalTranscript) {
            handleVoiceInput(finalTranscript.trim())
            setInterimTranscript("")
          }
        }

        recognition.onerror = (event) => {
          console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", event.error)
          setIsListening(false)
          setInterimTranscript("")

          // Only show errors that are not "no-speech" to reduce noise
          if (event.error === "not-allowed") {
            addMessage("system", "âŒ éŸ³å£°èªè­˜ã®è¨±å¯ãŒå¿…è¦ã§ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          } else if (event.error !== "no-speech" && event.error !== "aborted") {
            // Skip showing no-speech and aborted errors to reduce noise
            addMessage("system", `âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`)
          }
        }

        recognition.onend = () => {
          setIsListening(false)
          setInterimTranscript("")

          // Only restart if voice mode is still active and we're not intentionally stopping
          if (isVoiceMode) {
            // Add a small delay before restarting to prevent rapid restarts
            setTimeout(() => {
              try {
                if (isVoiceMode && recognitionRef.current === recognition) {
                  recognition.start()
                }
              } catch (error) {
                console.error("Failed to restart speech recognition:", error)
              }
            }, 1000)
          }
        }

        recognitionRef.current = recognition

        // Start recognition if voice mode is already active
        if (isVoiceMode && !isListening) {
          try {
            recognition.start()
          } catch (error) {
            console.error("Failed to start speech recognition:", error)
          }
        }
      } catch (error) {
        console.error("Speech recognition initialization error:", error)
        setCapabilities((prev) => ({ ...prev, speechRecognition: false }))
      }

      // Cleanup function
      return () => {
        if (recognitionRef.current) {
          try {
            recognitionRef.current.onend = null
            recognitionRef.current.onerror = null
            recognitionRef.current.onresult = null
            recognitionRef.current.onstart = null
            recognitionRef.current.stop()
          } catch (error) {
            console.error("Error cleaning up speech recognition:", error)
          }
        }
      }
    }
  }, [capabilities.speechRecognition, voiceLanguage, isVoiceMode])

  const addMessage = useCallback(
    (
      type: "user" | "ai" | "system" | "voice",
      content: string,
      isPeriodicAnalysis = false,
      isVoiceInput = false,
      hasImage = false,
      promptType?: string,
    ) => {
      const newMessage: ChatMessage = {
        id: `${Date.now()}-${Math.random()}`,
        type,
        content,
        timestamp: new Date(),
        isPeriodicAnalysis,
        isVoiceInput,
        hasImage,
        promptType,
      }
      setMessages((prev) => [...prev, newMessage])
    },
    [],
  )

  const stopCurrentAudio = () => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause()
      currentAudioRef.current.currentTime = 0
      currentAudioRef.current = null
    }
  }

  // éŸ³å£°å…¥åŠ›ã®å‡¦ç†
  const handleVoiceInput = async (transcript: string) => {
    addMessage("voice", transcript, false, true)

    // éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã®è§£æ
    const lowerTranscript = transcript.toLowerCase()

    if (
      lowerTranscript.includes("ç”»é¢å…±æœ‰") ||
      lowerTranscript.includes("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³") ||
      lowerTranscript.includes("ç”»é¢ã‚’å…±æœ‰")
    ) {
      addMessage("system", "ğŸ–¥ï¸ ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã—ã¾ã™...")
      setCaptureMode("screen")
      setTimeout(() => startCapture(), 1000)
    } else if (lowerTranscript.includes("ã‚«ãƒ¡ãƒ©") || lowerTranscript.includes("ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹")) {
      addMessage("system", "ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã—ã¾ã™...")
      setCaptureMode("camera")
      setTimeout(() => startCapture(), 1000)
    } else if (lowerTranscript.includes("ã‚«ãƒ¡ãƒ©åˆ‡æ›¿") || lowerTranscript.includes("ã‚«ãƒ¡ãƒ©ã‚’åˆ‡ã‚Šæ›¿ãˆ")) {
      if (capabilities.multipleCameras) {
        toggleCamera()
      } else {
        addMessage("system", "âš ï¸ ã‚«ãƒ¡ãƒ©ã®åˆ‡ã‚Šæ›¿ãˆã¯ã“ã®ãƒ‡ãƒã‚¤ã‚¹ã§ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
      }
    } else if (lowerTranscript.includes("åœæ­¢") || lowerTranscript.includes("æ­¢ã‚ã¦")) {
      addMessage("system", "â¹ï¸ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’åœæ­¢ã—ã¾ã™...")
      stopCapture()
    } else if (lowerTranscript.includes("éŸ³å£°å…¥åŠ›çµ‚äº†") || lowerTranscript.includes("éŸ³å£°ã‚’æ­¢ã‚ã¦")) {
      toggleVoiceMode()
    } else {
      // é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å‡¦ç†ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨ï¼‰
      await sendVoiceMessage(transcript)
    }
  }

  // ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½
  const toggleCamera = async () => {
    if (!capabilities.multipleCameras || !isCapturing || captureMode !== "camera") {
      return
    }

    // ç¾åœ¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
    if (stream) {
      stream.getTracks().forEach((track) => track.stop())
    }

    // ã‚«ãƒ¡ãƒ©ã®å‘ãã‚’åˆ‡ã‚Šæ›¿ãˆ
    const newFacingMode = facingMode === "user" ? "environment" : "user"
    setFacingMode(newFacingMode)

    try {
      const newStream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: newFacingMode,
          width: { ideal: 1280 },
          height: { ideal: 720 },
        },
        audio: false,
      })

      setStream(newStream)

      if (videoRef.current) {
        videoRef.current.srcObject = newStream
        await videoRef.current.play()
      }

      addMessage("system", `ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’${newFacingMode === "user" ? "ãƒ•ãƒ­ãƒ³ãƒˆ" : "ãƒªã‚¢"}ã‚«ãƒ¡ãƒ©ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚`)
    } catch (error) {
      console.error("ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆã‚¨ãƒ©ãƒ¼:", error)
      addMessage(
        "system",
        `âŒ ã‚«ãƒ¡ãƒ©ã®åˆ‡ã‚Šæ›¿ãˆã«å¤±æ•—ã—ã¾ã—ãŸ: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`,
      )
    }
  }

  // éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨ï¼‰
  const sendVoiceMessage = async (message: string) => {
    if (isSendingChat) return

    setIsSendingChat(true)

    try {
      // ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
      const base64Data = await captureCurrentFrame()

      const requestBody: any = {
        prompt: message,
        systemPrompt: SYSTEM_PROMPT,
        mimeType: "image/jpeg",
      }

      if (base64Data) {
        requestBody.image = base64Data
        addMessage("system", "ğŸ“¸ éŸ³å£°å…¥åŠ›ã¨ç¾åœ¨ã®ç”»åƒã‚’ä¸€ç·’ã«é€ä¿¡ä¸­...")
      } else {
        addMessage("system", "ğŸ’¬ éŸ³å£°å…¥åŠ›ã‚’é€ä¿¡ä¸­...")
      }

      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Language-Code": voiceLanguage,
        },
        body: JSON.stringify(requestBody),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", result.response, false, false, !!base64Data, "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")

        // éŸ³å£°ã§èª­ã¿ä¸Šã’ï¼ˆTTSãŒæœ‰åŠ¹ãªå ´åˆï¼‰
        if (result.response && isTTSEnabled) {
          speakText(result.response)
        }
      } else {
        addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: ${result.error}`)
        console.error("Chat error:", result.error)
      }
    } catch (error) {
      console.error("éŸ³å£°ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ éŸ³å£°ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`)
    } finally {
      setIsSendingChat(false)
    }
  }

  // ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
  const startScreenShare = async (): Promise<MediaStream> => {
    try {
      const mediaStream = await navigator.mediaDevices.getDisplayMedia({
        video: {
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          frameRate: { ideal: 30 },
        },
        audio: false,
      })

      mediaStream.getVideoTracks()[0].addEventListener("ended", () => {
        addMessage("system", "ç”»é¢å…±æœ‰ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸã€‚")
        stopCapture()
      })

      return mediaStream
    } catch (error) {
      // ãƒ¢ãƒã‚¤ãƒ«ã§ã®ç”»é¢å…±æœ‰ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹ç‰¹åˆ¥ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      if (isMobile) {
        console.error("Mobile screen sharing error:", error)
        throw new Error(
          "ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã®ç”»é¢å…±æœ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®åˆ¶é™ã«ã‚ˆã‚Šã€ä¸€éƒ¨ã®ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ç”»é¢å…±æœ‰ãŒåˆ©ç”¨ã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚",
        )
      }
      throw error
    }
  }

  // ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
  const startCamera = async (): Promise<MediaStream> => {
    const constraints = {
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        frameRate: { ideal: 30 },
        facingMode: facingMode, // Use the current facingMode state
      },
      audio: false,
    }

    try {
      const mediaStream = await navigator.mediaDevices.getUserMedia(constraints)
      return mediaStream
    } catch (error) {
      console.error("Camera access error:", error)

      // If we failed with the current facing mode, try the opposite as fallback
      if (isMobile && facingMode === "environment") {
        setFacingMode("user")
        addMessage("system", "âš ï¸ ãƒªã‚¢ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã‚’è©¦ã—ã¾ã™ã€‚")

        try {
          const fallbackStream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: "user",
              width: { ideal: 1280 },
              height: { ideal: 720 },
            },
            audio: false,
          })
          return fallbackStream
        } catch (fallbackError) {
          throw new Error("ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ã‚«ãƒ¡ãƒ©ã®è¨±å¯ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        }
      }

      throw error
    }
  }

  // ãƒ¡ã‚¤ãƒ³ã®ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹é–¢æ•°
  const startCapture = async () => {
    try {
      let mediaStream: MediaStream

      if (captureMode === "screen") {
        if (!capabilities.screenShare) {
          throw new Error("ç”»é¢å…±æœ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        }

        if (isMobile && !capabilities.mobileScreenShare) {
          addMessage(
            "system",
            "âš ï¸ ãŠä½¿ã„ã®ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ç”»é¢å…±æœ‰æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚",
          )
        }

        try {
          mediaStream = await startScreenShare()
          addMessage("system", "âœ… ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
        } catch (error: any) {
          console.error("Screen share error:", error)

          if (error.name === "NotAllowedError") {
            addMessage("system", "âš ï¸ ç”»é¢å…±æœ‰ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã§ç”»é¢å…±æœ‰ã‚’è¨±å¯ã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            throw new Error("ç”»é¢å…±æœ‰ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚")
          } else if (error.name === "NotSupportedError") {
            throw new Error("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯ç”»é¢å…±æœ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
          } else if (error.name === "AbortError") {
            addMessage("system", "âš ï¸ ç”»é¢å…±æœ‰ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
            throw new Error("ç”»é¢å…±æœ‰ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
          } else {
            throw new Error(`ç”»é¢å…±æœ‰ã‚¨ãƒ©ãƒ¼: ${error.message}`)
          }
        }
      } else {
        if (!capabilities.camera) {
          throw new Error("ã‚«ãƒ¡ãƒ©ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        }

        try {
          mediaStream = await startCamera()
          addMessage(
            "system",
            `âœ… ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚${isMobile && capabilities.multipleCameras ? `(${facingMode === "user" ? "ãƒ•ãƒ­ãƒ³ãƒˆ" : "ãƒªã‚¢"}ã‚«ãƒ¡ãƒ©ä½¿ç”¨ä¸­)` : ""}`,
          )
        } catch (error: any) {
          if (error.name === "NotAllowedError") {
            throw new Error("ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ã‚«ãƒ¡ãƒ©ã®è¨±å¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚")
          } else if (error.name === "NotFoundError") {
            throw new Error("ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          } else {
            throw new Error(`ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: ${error.message}`)
          }
        }
      }

      setStream(mediaStream)

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream
        await videoRef.current.play()
      }

      setIsCapturing(true)
      // å®šæœŸçš„ã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å®Ÿè¡Œï¼ˆé »åº¦ãŒ0ã‚ˆã‚Šå¤§ãã„å ´åˆã®ã¿ï¼‰
      if (Number.parseFloat(frequency) > 0) {
        // æœ€åˆã®ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å®Ÿè¡Œ
        setTimeout(() => captureAndAnalyze(), 2000)

        // å®šæœŸçš„ã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å®Ÿè¡Œ
        intervalRef.current = setInterval(() => {
          captureAndAnalyze()
        }, Number.parseFloat(frequency) * 1000)

        const currentPromptName = VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].name
        addMessage(
          "system",
          `${getLocalizedText("periodicAnalysisStarted", interfaceLanguage).replace(
            "{frequency}",
            frequency,
          )} (${currentPromptName}ãƒ¢ãƒ¼ãƒ‰)`,
        )
      } else {
        addMessage("system", getLocalizedText("noPeriodicAnalysis", interfaceLanguage))
      }
    } catch (error) {
      console.error("ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ ${error instanceof Error ? error.message : "ã‚­ãƒ£ãƒ—ãƒãƒ£ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"}`)

      // No automatic fallback - user must manually select camera mode
      if (captureMode === "screen") {
        addMessage("system", "ğŸ’¡ ç”»é¢å…±æœ‰ã«å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã€ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’æ‰‹å‹•ã§é¸æŠã—ã¦ãã ã•ã„ã€‚")
      }
    }
  }

  const stopCapture = () => {
    stopCurrentAudio()

    if (intervalRef.current) {
      clearInterval(intervalRef.current)
      intervalRef.current = null
    }

    if (stream) {
      stream.getTracks().forEach((track) => track.stop())
      setStream(null)
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null
    }

    setIsCapturing(false)
    addMessage("system", "ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
  }

  const captureCurrentFrame = async (): Promise<string | null> => {
    if (!videoRef.current || !canvasRef.current) {
      return null
    }

    const canvas = canvasRef.current
    const ctx = canvas.getContext("2d")
    if (!ctx) return null

    if (videoRef.current.readyState < 2) {
      return null
    }

    canvas.width = videoRef.current.videoWidth
    canvas.height = videoRef.current.videoHeight

    if (canvas.width === 0 || canvas.height === 0) {
      return null
    }

    ctx.drawImage(videoRef.current, 0, 0)

    const imageDataUrl = canvas.toDataURL("image/jpeg", 0.9)
    const base64Data = imageDataUrl.split(",")[1]

    return base64Data
  }

  const captureAndAnalyze = async () => {
    const currentPrompt = getCurrentVisualPrompt()
    if (!currentPrompt.trim() || isProcessing) {
      return
    }

    setIsProcessing(true)

    try {
      const base64Data = await captureCurrentFrame()
      if (!base64Data) {
        throw new Error("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã«å¤±æ•—ã—ã¾ã—ãŸ")
      }

      const promptName = VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].name
      addMessage("system", `ğŸ” å®šæœŸè§£æä¸­... (${promptName})`, true)

      const response = await fetch("/api/analyze-image", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Language-Code": voiceLanguage,
        },
        body: JSON.stringify({
          image: base64Data,
          prompt: currentPrompt,
          mimeType: "image/jpeg",
        }),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", `[${promptName}] ${result.analysis}`, true, false, true, promptName)

        if (result.analysis && isTTSEnabled) {
          speakText(result.analysis)
        }
      } else {
        addMessage("system", `âŒ å®šæœŸè§£æã‚¨ãƒ©ãƒ¼: ${result.error}`, true)
        console.error("Analysis error:", result.error)
      }
    } catch (error) {
      console.error("å®šæœŸè§£æã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ å®šæœŸè§£æã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`, true)
    } finally {
      setIsProcessing(false)
    }
  }

  const sendChatMessage = async () => {
    if (!chatMessage.trim() || isSendingChat) {
      return
    }

    const userMessage = chatMessage.trim()
    setChatMessage("")
    setIsSendingChat(true)

    try {
      addMessage("user", userMessage)

      const base64Data = await captureCurrentFrame()

      const requestBody: any = {
        prompt: userMessage,
        systemPrompt: SYSTEM_PROMPT,
        mimeType: "image/jpeg",
      }

      if (base64Data) {
        requestBody.image = base64Data
        addMessage("system", "ğŸ“¸ ç¾åœ¨ã®ç”»åƒã¨ä¸€ç·’ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
      } else {
        addMessage("system", "ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
      }

      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Language-Code": voiceLanguage,
        },
        body: JSON.stringify(requestBody),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", result.response, false, false, !!base64Data, "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")

        if (result.response && isTTSEnabled) {
          speakText(result.response)
        }
      } else {
        addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: ${result.error}`)
        console.error("Chat error:", result.error)
      }
    } catch (error) {
      console.error("ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`)
    } finally {
      setIsSendingChat(false)
    }
  }

  const speakText = async (text: string) => {
    try {
      stopCurrentAudio()

      const response = await fetch("/api/text-to-speech", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "X-Language-Code": voiceLanguage,
        },
        body: JSON.stringify({ text }),
      })

      if (response.ok) {
        const audioBlob = await response.blob()
        const audioUrl = URL.createObjectURL(audioBlob)
        const audio = new Audio(audioUrl)

        currentAudioRef.current = audio

        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          currentAudioRef.current = null
        }

        audio.onerror = () => {
          URL.revokeObjectURL(audioUrl)
          currentAudioRef.current = null
        }

        await audio.play()
      } else {
        console.error("TTS API error:", await response.text())
      }
    } catch (error) {
      console.error("éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:", error)
    }
  }

  const toggleVoiceMode = () => {
    if (!capabilities.speechRecognition) {
      addMessage("system", "âŒ éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
      return
    }

    if (isVoiceMode) {
      setIsVoiceMode(false)
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop()
        } catch (error) {
          console.error("Error stopping speech recognition:", error)
        }
      }
      addMessage("system", "ğŸ”‡ éŸ³å£°å…¥åŠ›ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")
    } else {
      setIsVoiceMode(true)
      if (recognitionRef.current && !isListening) {
        try {
          recognitionRef.current.start()
        } catch (error) {
          console.error("Error starting speech recognition:", error)
          addMessage("system", "âŒ éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        }
      }
      addMessage(
        "system",
        "ğŸ¤ éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã€Œç”»é¢å…±æœ‰ã€ã€Œã‚«ãƒ¡ãƒ©ã€ã€Œåœæ­¢ã€ãªã©ã®éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ãŒåˆ©ç”¨ã§ãã¾ã™ã€‚",
      )
    }
  }

  const toggleListening = () => {
    if (!recognitionRef.current) {
      addMessage("system", "âŒ éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
      return
    }

    if (isListening) {
      try {
        recognitionRef.current.stop()
      } catch (error) {
        console.error("Error stopping speech recognition:", error)
      }
    } else {
      try {
        recognitionRef.current.start()
      } catch (error) {
        console.error("Error starting speech recognition:", error)
        addMessage("system", "âŒ éŸ³å£°èªè­˜ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
      }
    }
  }

  const manualCapture = () => {
    if (isCapturing && !isProcessing) {
      captureAndAnalyze()
    }
  }

  const handleChatKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault()
      sendChatMessage()
    }
  }

  const toggleTTS = () => {
    if (!isTTSEnabled) {
      setIsTTSEnabled(true)
      addMessage("system", "ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’ã‚’æœ‰åŠ¹ã«ã—ã¾ã—ãŸã€‚")
    } else {
      setIsTTSEnabled(false)
      stopCurrentAudio()
      addMessage("system", "ğŸ”‡ éŸ³å£°èª­ã¿ä¸Šã’ã‚’ç„¡åŠ¹ã«ã—ã¾ã—ãŸã€‚")
    }
  }

  const handleCaptureModeChange = (value: "camera" | "screen") => {
    if (value === "screen") {
      if (!capabilities.screenShare) {
        addMessage("system", "âš ï¸ ç”»é¢å…±æœ‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        return
      }

      if (isMobile && !capabilities.mobileScreenShare) {
        addMessage("system", "âš ï¸ ãŠä½¿ã„ã®ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ç”»é¢å…±æœ‰æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
      }
    }
    setCaptureMode(value)
  }

  // APIçŠ¶æ…‹
  const [apiStatus, setApiStatus] = useState<{
    gemini: boolean
    tts: boolean
    message: string
  }>({ gemini: false, tts: false, message: "è¨­å®šã‚’ç¢ºèªä¸­..." })

  // Localization function
  const getLocalizedText = (key: string, lang: string) => {
    const translations: Record<string, Record<string, string>> = {
      periodicAnalysisStarted: {
        ja: "{frequency}ç§’é–“éš”ã§ç”»åƒè§£æã‚’é–‹å§‹ã—ã¾ã™ã€‚éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚",
        en: "Starting image analysis at {frequency} second intervals. Voice commands are also available.",
        zh: "å¼€å§‹æ¯{frequency}ç§’è¿›è¡Œä¸€æ¬¡å›¾åƒåˆ†æã€‚è¯­éŸ³å‘½ä»¤ä¹Ÿå¯ç”¨ã€‚",
        ko: "{frequency}ì´ˆ ê°„ê²©ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. ìŒì„± ëª…ë ¹ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.",
      },
      noPeriodicAnalysis: {
        ja: "å®šæœŸè§£æãªã—ã§é–‹å§‹ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§è§£æã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚",
        en: "Started without periodic analysis. You can run analysis manually.",
        zh: "å·²å¼€å§‹ï¼Œæ— å®šæœŸåˆ†æã€‚æ‚¨å¯ä»¥æ‰‹åŠ¨è¿è¡Œåˆ†æã€‚",
        ko: "ì •ê¸° ë¶„ì„ ì—†ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      },
      realTimeChat: {
        ja: "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆ",
        en: "Real-time Chat",
        zh: "å®æ—¶èŠå¤©",
        ko: "ì‹¤ì‹œê°„ ì±„íŒ…",
      },
      enterMessage: {
        ja: "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„... (Enterã§é€ä¿¡ã€Shift+Enterã§æ”¹è¡Œ)",
        en: "Enter your message... (Enter to send, Shift+Enter for new line)",
        zh: "è¾“å…¥æ‚¨çš„æ¶ˆæ¯... (æŒ‰Enterå‘é€ï¼ŒShift+Enteræ¢è¡Œ)",
        ko: "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (Enterë¡œ ì „ì†¡, Shift+Enterë¡œ ì¤„ë°”ê¿ˆ)",
      },
      sending: {
        ja: "é€ä¿¡ä¸­...",
        en: "Sending...",
        zh: "å‘é€ä¸­...",
        ko: "ì „ì†¡ ì¤‘...",
      },
      processing: {
        ja: "å‡¦ç†ä¸­...",
        en: "Processing...",
        zh: "å¤„ç†ä¸­...",
        ko: "ì²˜ë¦¬ ì¤‘...",
      },
      analyzeNow: {
        ja: "ä»Šã™ãè§£æ",
        en: "Analyze Now",
        zh: "ç«‹å³åˆ†æ",
        ko: "ì§€ê¸ˆ ë¶„ì„",
      },
      stop: {
        ja: "åœæ­¢",
        en: "Stop",
        zh: "åœæ­¢",
        ko: "ì¤‘ì§€",
      },
      start: {
        ja: "é–‹å§‹",
        en: "Start",
        zh: "å¼€å§‹",
        ko: "ì‹œì‘",
      },
      camera: {
        ja: "ã‚«ãƒ¡ãƒ©",
        en: "Camera",
        zh: "ç›¸æœº",
        ko: "ì¹´ë©”ë¼",
      },
      screenShare: {
        ja: "ç”»é¢å…±æœ‰",
        en: "Screen Share",
        zh: "å±å¹•å…±äº«",
        ko: "í™”ë©´ ê³µìœ ",
      },
      captureMode: {
        ja: "ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰",
        en: "Capture Mode",
        zh: "æ•è·æ¨¡å¼",
        ko: "ìº¡ì²˜ ëª¨ë“œ",
      },
      periodicPrompt: {
        ja: "å®šæœŸè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        en: "Periodic Analysis Prompt",
        zh: "å®šæœŸåˆ†ææç¤º",
        ko: "ì •ê¸° ë¶„ì„ í”„ë¡¬í”„íŠ¸",
      },
      captureFrequency: {
        ja: "ã‚­ãƒ£ãƒ—ãƒãƒ£é »åº¦",
        en: "Capture Frequency",
        zh: "æ•è·é¢‘ç‡",
        ko: "ìº¡ì²˜ ë¹ˆë„",
      },
      languageSettings: {
        ja: "è¨€èªè¨­å®š",
        en: "Language Settings",
        zh: "è¯­è¨€è®¾ç½®",
        ko: "ì–¸ì–´ ì„¤ì •",
      },
      noPeriodicAnalysisOption: {
        ja: "å®šæœŸè§£æãªã—",
        en: "No periodic analysis",
        zh: "æ— å®šæœŸåˆ†æ",
        ko: "ì •ê¸° ë¶„ì„ ì—†ìŒ",
      },
      seconds: {
        ja: "ç§’",
        en: "seconds",
        zh: "ç§’",
        ko: "ì´ˆ",
      },
    }

    return translations[key]?.[lang] || translations[key]?.["en"] || key
  }

  return (
    <div className="min-h-screen bg-gray-50 p-4">
      <div className="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-3 gap-6">
        {/* å·¦å´: ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ« */}
        <Card className="lg:col-span-1 self-start sticky top-4">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <Camera className="w-5 h-5" />
              AI Vision Chat
            </CardTitle>
          </CardHeader>
          <CardContent className="space-y-6">
            {/* APIçŠ¶æ…‹è¡¨ç¤º */}
            <Alert>
              <AlertCircle className="h-4 w-4" />
              <AlertDescription className="flex items-center gap-2">
                {apiStatus.gemini && apiStatus.tts ? (
                  <CheckCircle className="w-4 h-4 text-green-500" />
                ) : (
                  <AlertCircle className="w-4 h-4 text-yellow-500" />
                )}
                {apiStatus.message}
              </AlertDescription>
            </Alert>

            {/* éŸ³å£°å…¥åŠ›çŠ¶æ…‹ */}
            {capabilities.speechRecognition && (
              <Alert>
                <Headphones className="h-4 w-4" />
                <AlertDescription>
                  <div className="flex items-center justify-between">
                    <span className="text-sm">
                      éŸ³å£°å…¥åŠ›: {isVoiceMode ? "æœ‰åŠ¹" : "ç„¡åŠ¹"}
                      {isListening && " (èãå–ã‚Šä¸­...)"}
                    </span>
                    <Button variant={isVoiceMode ? "destructive" : "outline"} size="sm" onClick={toggleVoiceMode}>
                      {isVoiceMode ? (
                        <Mic className="w-3 h-3 text-gray-500" />
                      ) : (
                        <MicOff className="w-3 h-3 text-red-500" />
                      )}
                    </Button>
                  </div>
                  {interimTranscript && (
                    <div className="mt-2 p-2 bg-blue-50 rounded text-xs">èªè­˜ä¸­: "{interimTranscript}"</div>
                  )}
                </AlertDescription>
              </Alert>
            )}

            {/* è¨€èªè¨­å®š */}
            {capabilities.speechRecognition && (
              <div>
                <Label className="text-base font-medium flex items-center gap-2">
                  <Settings className="w-4 h-4" />
                  {getLocalizedText("languageSettings", interfaceLanguage)}
                </Label>
                <div className="space-y-2 mt-2">
                  <Select
                    value={interfaceLanguage}
                    onValueChange={(value) => {
                      setInterfaceLanguage(value)
                      // Set voice language based on interface language
                      switch (value) {
                        case "ja":
                          setVoiceLanguage("ja-JP")
                          break
                        case "en":
                          setVoiceLanguage("en-US")
                          break
                        case "zh":
                          setVoiceLanguage("zh-CN")
                          break
                        case "ko":
                          setVoiceLanguage("ko-KR")
                          break
                        default:
                          setVoiceLanguage("ja-JP")
                      }
                    }}
                  >
                    <SelectTrigger>
                      <SelectValue />
                    </SelectTrigger>
                    <SelectContent>
                      <SelectItem value="ja">æ—¥æœ¬èª</SelectItem>
                      <SelectItem value="en">English</SelectItem>
                      <SelectItem value="zh">ä¸­æ–‡</SelectItem>
                      <SelectItem value="ko">í•œêµ­ì–´</SelectItem>
                    </SelectContent>
                  </Select>
                </div>
              </div>
            )}

            {/* æ©Ÿèƒ½ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ */}
            <Alert>
              <Info className="h-4 w-4" />
              <AlertDescription>
                <div className="text-sm">
                  <div className="font-medium mb-2">æ©Ÿèƒ½çŠ¶æ³:</div>
                  <div className="space-y-1">
                    <div className="flex items-center gap-2">
                      <Camera className="w-3 h-3" />
                      <span className={capabilities.camera ? "text-green-600" : "text-red-600"}>
                        ã‚«ãƒ¡ãƒ©: {capabilities.camera ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                        {capabilities.camera && capabilities.multipleCameras && " (è¤‡æ•°ã‚«ãƒ¡ãƒ©å¯¾å¿œ)"}
                      </span>
                    </div>
                    <div className="flex items-center gap-2">
                      <Monitor className="w-3 h-3" />
                      <span className={capabilities.screenShare ? "text-green-600" : "text-red-600"}>
                        ç”»é¢å…±æœ‰: {capabilities.screenShare ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                        {capabilities.screenShare && isMobile && !capabilities.mobileScreenShare && " (åˆ¶é™ã‚ã‚Š)"}
                      </span>
                    </div>
                    <div className="flex items-center gap-2">
                      <Mic className="w-3 h-3" />
                      <span className={capabilities.speechRecognition ? "text-green-600" : "text-red-600"}>
                        éŸ³å£°èªè­˜: {capabilities.speechRecognition ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                      </span>
                    </div>
                    {isMobile && (
                      <div className="flex items-center gap-2">
                        <Smartphone className="w-3 h-3" />
                        <span className="text-blue-600">ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡ºæ¸ˆã¿</span>
                      </div>
                    )}
                  </div>
                  {capabilities.speechRecognition && (
                    <div className="mt-2 p-2 bg-blue-50 rounded text-xs">
                      ğŸ’¡ éŸ³å£°ã‚³ãƒãƒ³ãƒ‰: ã€Œç”»é¢å…±æœ‰ã€ã€Œã‚«ãƒ¡ãƒ©ã€ã€Œåœæ­¢ã€ã€ŒéŸ³å£°å…¥åŠ›çµ‚äº†ã€
                      {capabilities.multipleCameras && "ã€Œã‚«ãƒ¡ãƒ©åˆ‡æ›¿ã€"}
                    </div>
                  )}
                </div>
              </AlertDescription>
            </Alert>

            {/* ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰é¸æŠ */}
            <div>
              <Label className="text-base font-medium">{getLocalizedText("captureMode", interfaceLanguage)}</Label>
              <RadioGroup
                value={captureMode}
                onValueChange={handleCaptureModeChange}
                className="flex gap-6 mt-2"
                disabled={isCapturing}
              >
                <div className="flex items-center space-x-2">
                  <RadioGroupItem value="camera" id="camera" disabled={!capabilities.camera} />
                  <Label
                    htmlFor="camera"
                    className={`flex items-center gap-2 ${!capabilities.camera ? "opacity-50" : ""}`}
                  >
                    <Camera className="w-4 h-4" />
                    {getLocalizedText("camera", interfaceLanguage)}
                  </Label>
                </div>
                <div className="flex items-center space-x-2">
                  <RadioGroupItem value="screen" id="screen" disabled={!capabilities.screenShare} />
                  <Label
                    htmlFor="screen"
                    className={`flex items-center gap-2 ${!capabilities.screenShare ? "opacity-50" : ""}`}
                  >
                    <Monitor className="w-4 h-4" />
                    {getLocalizedText("screenShare", interfaceLanguage)}
                  </Label>
                </div>
              </RadioGroup>
            </div>

            {/* ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³ (ãƒ¢ãƒã‚¤ãƒ«ã‹ã¤è¤‡æ•°ã‚«ãƒ¡ãƒ©ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º) */}
            {isMobile && capabilities.multipleCameras && captureMode === "camera" && (
              <div>
                <Button
                  onClick={toggleCamera}
                  variant="outline"
                  className="w-full"
                  disabled={!capabilities.multipleCameras || isCapturing === false}
                >
                  <FlipHorizontal className="w-4 h-4 mr-2" />
                  {facingMode === "user" ? "ãƒªã‚¢ã‚«ãƒ¡ãƒ©ã«åˆ‡æ›¿" : "ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã«åˆ‡æ›¿"}
                </Button>
              </div>
            )}

            {/* ç”»åƒè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ */}
            <div>
              <Label className="text-base font-medium flex items-center gap-2">
                <Eye className="w-4 h-4" />
                ç”»åƒè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
              </Label>
              <Select
                value={visualAnalysisType}
                onValueChange={(value: keyof typeof VISUAL_ANALYSIS_PROMPTS) => setVisualAnalysisType(value)}
                disabled={isCapturing}
              >
                <SelectTrigger className="mt-2">
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  {Object.entries(VISUAL_ANALYSIS_PROMPTS).map(([key, config]) => (
                    <SelectItem key={key} value={key}>
                      <div className="flex items-center gap-2">
                        {config.icon}
                        <div>
                          <div className="font-medium">{config.name}</div>
                          <div className="text-xs text-gray-500">{config.description}</div>
                        </div>
                      </div>
                    </SelectItem>
                  ))}
                </SelectContent>
              </Select>

              {/* é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¬æ˜ */}
              <div className="mt-2 p-3 bg-blue-50 rounded-lg text-sm">
                <div className="flex items-center gap-2 font-medium text-blue-800 mb-1">
                  {VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].icon}
                  {VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].name}
                </div>
                <div className="text-blue-700 text-xs mb-2">
                  {VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].description}
                </div>
                {visualAnalysisType !== "custom" && (
                  <div className="text-blue-600 text-xs bg-white p-2 rounded border">
                    {VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].prompt}
                  </div>
                )}
              </div>
            </div>

            {/* ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ› */}
            {visualAnalysisType === "custom" && (
              <div>
                <Label htmlFor="customPrompt" className="text-base font-medium flex items-center gap-2">
                  <FileText className="w-4 h-4" />
                  ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                </Label>
                <Textarea
                  id="customPrompt"
                  value={customPrompt}
                  onChange={(e) => setCustomPrompt(e.target.value)}
                  placeholder="ç‹¬è‡ªã®ç”»åƒè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
                  className="mt-2 min-h-[80px]"
                  disabled={isCapturing}
                />
              </div>
            )}

            {/* ã‚­ãƒ£ãƒ—ãƒãƒ£é »åº¦ */}
            <div>
              <Label className="text-base font-medium">{getLocalizedText("captureFrequency", interfaceLanguage)}</Label>
              <Select value={frequency} onValueChange={setFrequency} disabled={isCapturing}>
                <SelectTrigger className="mt-2">
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="0">{getLocalizedText("noPeriodicAnalysisOption", interfaceLanguage)}</SelectItem>
                  <SelectItem value="0.5">0.5 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="1">1 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="3">3 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="5">5 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="10">10 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="20">20 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                  <SelectItem value="30">30 {getLocalizedText("seconds", interfaceLanguage)}</SelectItem>
                </SelectContent>
              </Select>
            </div>

            {/* ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ */}
            <div className="space-y-2">
              <div className="flex gap-2">
                <Button
                  onClick={isCapturing ? stopCapture : startCapture}
                  disabled={
                    (visualAnalysisType === "custom" && !customPrompt.trim()) ||
                    (visualAnalysisType !== "custom" && !getCurrentVisualPrompt().trim()) ||
                    !apiStatus.gemini ||
                    !apiStatus.tts ||
                    (!capabilities.camera && !capabilities.screenShare)
                  }
                  className="flex-1"
                  size="lg"
                >
                  {isCapturing ? (
                    <>
                      <Square className="w-4 h-4 mr-2" />
                      {getLocalizedText("stop", interfaceLanguage)}
                    </>
                  ) : (
                    <>
                      <Play className="w-4 h-4 mr-2" />
                      {getLocalizedText("start", interfaceLanguage)}
                    </>
                  )}
                </Button>

                <Button onClick={toggleTTS} variant="outline" size="lg">
                  {isTTSEnabled ? <Volume2 className="w-4 h-4" /> : <VolumeX className="w-4 h-4" />}
                </Button>
              </div>

              {isCapturing && Number.parseFloat(frequency) >= 0 && (
                <Button onClick={manualCapture} disabled={isProcessing} variant="outline" className="w-full">
                  {isProcessing
                    ? getLocalizedText("processing", interfaceLanguage)
                    : getLocalizedText("analyzeNow", interfaceLanguage)}
                </Button>
              )}
            </div>

            {/* ãƒ“ãƒ‡ã‚ªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */}
            <div className="relative">
              <video
                ref={videoRef}
                className="w-full rounded-lg bg-black"
                style={{ maxHeight: "200px" }}
                muted
                playsInline
              />
              <canvas ref={canvasRef} className="hidden" />
              {isProcessing && (
                <div className="absolute inset-0 bg-black bg-opacity-50 flex items-center justify-center rounded-lg">
                  <div className="text-white text-sm">è§£æä¸­...</div>
                </div>
              )}
              {isCapturing && (
                <div className="absolute top-2 left-2 bg-red-500 text-white px-2 py-1 rounded text-xs">
                  {captureMode === "screen" ? "ç”»é¢å…±æœ‰ä¸­" : "ã‚«ãƒ¡ãƒ©æ’®å½±ä¸­"}
                  {captureMode === "camera" &&
                    isMobile &&
                    capabilities.multipleCameras &&
                    ` (${facingMode === "user" ? "ãƒ•ãƒ­ãƒ³ãƒˆ" : "ãƒªã‚¢"})`}
                </div>
              )}
              {isVoiceMode && (
                <div className="absolute top-2 right-2 bg-blue-500 text-white px-2 py-1 rounded text-xs flex items-center gap-1">
                  <Mic className="w-3 h-3" />
                  éŸ³å£°å…¥åŠ›
                </div>
              )}
              {isCapturing && (
                <div className="absolute bottom-2 left-2 bg-purple-500 text-white px-2 py-1 rounded text-xs">
                  {VISUAL_ANALYSIS_PROMPTS[visualAnalysisType].name}
                </div>
              )}
            </div>
          </CardContent>
        </Card>

        {/* å³å´: ãƒãƒ£ãƒƒãƒˆç”»é¢ - é«˜ã•ã‚’ç”»é¢ã„ã£ã±ã„ã«æ‹¡å¼µ */}
        <Card className="lg:col-span-2 flex flex-col" style={{ minHeight: "calc(100vh - 2rem)" }}>
          <CardHeader className="pb-2">
            <CardTitle className="flex items-center gap-2">
              <MessageSquare className="w-5 h-5" />
              é¡§å®¢ã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ
            </CardTitle>
          </CardHeader>
          <CardContent className="flex flex-col flex-grow p-4 pt-0">
            {/* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã‚¨ãƒªã‚¢ - é«˜ã•ã‚’è‡ªå‹•èª¿æ•´ */}
            <ScrollArea className="flex-grow pr-4 mb-4">
              <div className="space-y-4">
                {messages.map((message) => (
                  <div
                    key={message.id}
                    className={`flex ${message.type === "user" || message.type === "voice" ? "justify-end" : "justify-start"}`}
                  >
                    <div
                      className={`max-w-[80%] p-3 rounded-lg ${
                        message.type === "user"
                          ? "bg-blue-500 text-white"
                          : message.type === "voice"
                            ? "bg-purple-500 text-white"
                            : message.type === "system"
                              ? "bg-gray-100 text-gray-700 border"
                              : message.isPeriodicAnalysis
                                ? "bg-purple-100 text-purple-800 border border-purple-200"
                                : "bg-green-100 text-green-800"
                      }`}
                    >
                      <p className="text-sm whitespace-pre-wrap">{message.content}</p>
                      <div className="flex items-center justify-between mt-1">
                        <p className="text-xs opacity-70">{message.timestamp.toLocaleTimeString()}</p>
                        <div className="flex items-center gap-1">
                          {message.isVoiceInput && (
                            <span className="text-xs bg-purple-200 text-purple-700 px-2 py-1 rounded">éŸ³å£°å…¥åŠ›</span>
                          )}
                          {message.isPeriodicAnalysis && (
                            <span className="text-xs bg-purple-200 text-purple-700 px-2 py-1 rounded">å®šæœŸè§£æ</span>
                          )}
                          {message.hasImage && (
                            <span className="text-xs bg-blue-200 text-blue-700 px-2 py-1 rounded">ç”»åƒä»˜ã</span>
                          )}
                          {message.promptType && (
                            <span className="text-xs bg-gray-200 text-gray-700 px-2 py-1 rounded">
                              {message.promptType}
                            </span>
                          )}
                        </div>
                      </div>
                    </div>
                  </div>
                ))}
                <div ref={messagesEndRef} />
              </div>
            </ScrollArea>

            {/* ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ - ä¸‹éƒ¨ã«å›ºå®š */}
            <div className="border-t pt-4 mt-auto">
              <Label htmlFor="chatMessage" className="text-sm font-medium flex items-center gap-2 mb-2">
                <MessageSquare className="w-4 h-4" />
                {getLocalizedText("realTimeChat", interfaceLanguage)}
              </Label>
              <div className="flex gap-2">
                <div className="relative flex-1">
                  <Textarea
                    id="chatMessage"
                    value={chatMessage}
                    onChange={(e) => setChatMessage(e.target.value)}
                    onKeyPress={handleChatKeyPress}
                    placeholder={getLocalizedText("enterMessage", interfaceLanguage)}
                    className="flex-1 min-h-[60px] max-h-[120px] pr-10"
                    disabled={isSendingChat}
                  />
                  {capabilities.speechRecognition && (
                    <Button
                      variant="ghost"
                      size="sm"
                      onClick={toggleListening}
                      disabled={!capabilities.speechRecognition}
                      className="absolute right-2 bottom-2 h-8 w-8 p-0"
                    >
                      {isListening ? (
                        <Mic className="w-4 h-4 text-gray-500" />
                      ) : (
                        <MicOff className="w-4 h-4 text-red-500" />
                      )}
                    </Button>
                  )}
                </div>
                <Button
                  onClick={sendChatMessage}
                  disabled={!chatMessage.trim() || isSendingChat || !apiStatus.gemini}
                  size="sm"
                  className="h-auto"
                >
                  {isSendingChat ? (
                    getLocalizedText("sending", interfaceLanguage)
                  ) : (
                    <>
                      <Send className="w-4 h-4" />
                    </>
                  )}
                </Button>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  )
}
