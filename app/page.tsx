"use client"

import type React from "react"

import { useState, useRef, useEffect, useCallback } from "react"
import { Button } from "@/components/ui/button"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import { Label } from "@/components/ui/label"
import { RadioGroup, RadioGroupItem } from "@/components/ui/radio-group"
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select"
import { ScrollArea } from "@/components/ui/scroll-area"
import { Alert, AlertDescription } from "@/components/ui/alert"
import { Textarea } from "@/components/ui/textarea"
import {
  Mic,
  MicOff,
  Play,
  Square,
  Camera,
  Monitor,
  AlertCircle,
  CheckCircle,
  Send,
  Volume2,
  VolumeX,
  MessageSquare,
  Eye,
  Info,
  Headphones,
  Settings,
} from "lucide-react"

interface ChatMessage {
  id: string
  type: "user" | "ai" | "system" | "voice"
  content: string
  timestamp: Date
  isPeriodicAnalysis?: boolean
  isVoiceInput?: boolean
  hasImage?: boolean
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  start(): void
  stop(): void
  onresult: (event: any) => void
  onerror: (event: any) => void
  onend: () => void
  onstart: () => void
}

declare global {
  interface Window {
    webkitSpeechRecognition: new () => SpeechRecognition
    SpeechRecognition: new () => SpeechRecognition
  }
}

export default function AIVisionChat() {
  const [captureMode, setCaptureMode] = useState<"camera" | "screen">("camera")
  const [periodicPrompt, setPeriodicPrompt] = useState("ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ")
  const [chatMessage, setChatMessage] = useState("")
  const [frequency, setFrequency] = useState("10")
  const [isCapturing, setIsCapturing] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [isSendingChat, setIsSendingChat] = useState(false)
  const [isTTSEnabled, setIsTTSEnabled] = useState(true)
  const [isVoiceMode, setIsVoiceMode] = useState(false)
  const [voiceLanguage, setVoiceLanguage] = useState("ja-JP")
  const [messages, setMessages] = useState<ChatMessage[]>([])
  const [stream, setStream] = useState<MediaStream | null>(null)
  const [interimTranscript, setInterimTranscript] = useState("")
  const [voiceConfidence, setVoiceConfidence] = useState(0)
  const [capabilities, setCapabilities] = useState({
    camera: false,
    screenShare: false,
    speechRecognition: false,
  })
  const [apiStatus, setApiStatus] = useState<{
    gemini: boolean
    tts: boolean
    message: string
  }>({ gemini: false, tts: false, message: "è¨­å®šã‚’ç¢ºèªä¸­..." })

  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const intervalRef = useRef<NodeJS.Timeout | null>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)
  const currentAudioRef = useRef<HTMLAudioElement | null>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)

  // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æœ€ä¸‹éƒ¨ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }

  useEffect(() => {
    scrollToBottom()
  }, [messages])

  // ãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½ã®æ¤œå‡º
  useEffect(() => {
    const checkCapabilities = async () => {
      const caps = {
        camera: false,
        screenShare: false,
        speechRecognition: false,
      }

      // ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã®ç¢ºèª
      try {
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          caps.camera = true
        }
      } catch (error) {
        console.log("Camera not supported:", error)
      }

      // ç”»é¢å…±æœ‰ã®ç¢ºèª
      try {
        if (
          navigator.mediaDevices &&
          navigator.mediaDevices.getDisplayMedia &&
          typeof navigator.mediaDevices.getDisplayMedia === "function"
        ) {
          caps.screenShare = true
        }
      } catch (error) {
        console.log("Screen share not supported:", error)
      }

      // éŸ³å£°èªè­˜ã®ç¢ºèª
      if (typeof window !== "undefined") {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
        if (SpeechRecognition) {
          caps.speechRecognition = true
        }
      }

      setCapabilities(caps)

      // åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
      const availableFeatures = []
      if (caps.camera) availableFeatures.push("ã‚«ãƒ¡ãƒ©")
      if (caps.screenShare) availableFeatures.push("ç”»é¢å…±æœ‰")
      if (caps.speechRecognition) availableFeatures.push("éŸ³å£°èªè­˜")

      if (availableFeatures.length > 0) {
        addMessage("system", `âœ… åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½: ${availableFeatures.join(", ")}`)
        if (caps.speechRecognition) {
          addMessage("system", "ğŸ¤ éŸ³å£°å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹ã«ã—ã¦ã€å£°ã§æ“ä½œã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        }
      } else {
        addMessage("system", "âš ï¸ ãƒ¡ãƒ‡ã‚£ã‚¢æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚")
      }
    }

    checkCapabilities()
  }, [])

  // APIè¨­å®šãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    const checkApiStatus = async () => {
      try {
        const response = await fetch("/api/config")
        const config = await response.json()
        setApiStatus(config)

        if (config.gemini && config.tts) {
          addMessage("system", "âœ… APIè¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚")
        } else {
          addMessage("system", `âš ï¸ ${config.message}`)
        }
      } catch (error) {
        console.error("APIè¨­å®šãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼:", error)
        addMessage("system", "âŒ APIè¨­å®šã®ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
      }
    }

    checkApiStatus()
  }, [])

  // éŸ³å£°èªè­˜ã®åˆæœŸåŒ–
  useEffect(() => {
    if (capabilities.speechRecognition) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      const recognition = new SpeechRecognition()
      recognition.continuous = true
      recognition.interimResults = true
      recognition.lang = voiceLanguage

      recognition.onstart = () => {
        setIsListening(true)
        addMessage("system", "ğŸ¤ éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚")
      }

      recognition.onresult = (event) => {
        let interimTranscript = ""
        let finalTranscript = ""

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript
          const confidence = event.results[i][0].confidence

          if (event.results[i].isFinal) {
            finalTranscript += transcript
            setVoiceConfidence(confidence || 0)
          } else {
            interimTranscript += transcript
          }
        }

        setInterimTranscript(interimTranscript)

        if (finalTranscript) {
          handleVoiceInput(finalTranscript.trim())
          setInterimTranscript("")
        }
      }

      recognition.onerror = (event) => {
        console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", event.error)
        setIsListening(false)
        setInterimTranscript("")

        if (event.error === "not-allowed") {
          addMessage("system", "âŒ éŸ³å£°èªè­˜ã®è¨±å¯ãŒå¿…è¦ã§ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        } else if (event.error === "no-speech") {
          addMessage("system", "âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
        } else {
          addMessage("system", `âŒ éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: ${event.error}`)
        }
      }

      recognition.onend = () => {
        setIsListening(false)
        setInterimTranscript("")
        if (isVoiceMode) {
          // éŸ³å£°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã¯è‡ªå‹•çš„ã«å†é–‹
          setTimeout(() => {
            if (isVoiceMode && !isListening) {
              recognition.start()
            }
          }, 1000)
        }
      }

      recognitionRef.current = recognition
    }
  }, [capabilities.speechRecognition, voiceLanguage, isVoiceMode])

  const addMessage = useCallback(
    (
      type: "user" | "ai" | "system" | "voice",
      content: string,
      isPeriodicAnalysis = false,
      isVoiceInput = false,
      hasImage = false,
    ) => {
      const newMessage: ChatMessage = {
        id: `${Date.now()}-${Math.random()}`,
        type,
        content,
        timestamp: new Date(),
        isPeriodicAnalysis,
        isVoiceInput,
        hasImage,
      }
      setMessages((prev) => [...prev, newMessage])
    },
    [],
  )

  const stopCurrentAudio = () => {
    if (currentAudioRef.current) {
      currentAudioRef.current.pause()
      currentAudioRef.current.currentTime = 0
      currentAudioRef.current = null
    }
  }

  // éŸ³å£°å…¥åŠ›ã®å‡¦ç†
  const handleVoiceInput = async (transcript: string) => {
    addMessage("voice", transcript, false, true)

    // éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã®è§£æ
    const lowerTranscript = transcript.toLowerCase()

    if (
      lowerTranscript.includes("ç”»é¢å…±æœ‰") ||
      lowerTranscript.includes("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³") ||
      lowerTranscript.includes("ç”»é¢ã‚’å…±æœ‰")
    ) {
      addMessage("system", "ğŸ–¥ï¸ ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã—ã¾ã™...")
      setCaptureMode("screen")
      setTimeout(() => startCapture(), 1000)
    } else if (lowerTranscript.includes("ã‚«ãƒ¡ãƒ©") || lowerTranscript.includes("ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹")) {
      addMessage("system", "ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã—ã¾ã™...")
      setCaptureMode("camera")
      setTimeout(() => startCapture(), 1000)
    } else if (lowerTranscript.includes("åœæ­¢") || lowerTranscript.includes("æ­¢ã‚ã¦")) {
      addMessage("system", "â¹ï¸ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’åœæ­¢ã—ã¾ã™...")
      stopCapture()
    } else if (lowerTranscript.includes("éŸ³å£°ãƒ¢ãƒ¼ãƒ‰çµ‚äº†") || lowerTranscript.includes("éŸ³å£°ã‚’æ­¢ã‚ã¦")) {
      toggleVoiceMode()
    } else {
      // é€šå¸¸ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦å‡¦ç†
      await sendVoiceMessage(transcript)
    }
  }

  // éŸ³å£°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡
  const sendVoiceMessage = async (message: string) => {
    if (isSendingChat) return

    setIsSendingChat(true)

    try {
      // ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
      const base64Data = await captureCurrentFrame()

      const requestBody: any = {
        prompt: message,
        mimeType: "image/jpeg",
      }

      if (base64Data) {
        requestBody.image = base64Data
        addMessage("system", "ğŸ“¸ éŸ³å£°å…¥åŠ›ã¨ç¾åœ¨ã®ç”»åƒã‚’ä¸€ç·’ã«é€ä¿¡ä¸­...")
      } else {
        addMessage("system", "ğŸ’¬ éŸ³å£°å…¥åŠ›ã‚’é€ä¿¡ä¸­...")
      }

      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(requestBody),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", result.response, false, false, !!base64Data)

        // éŸ³å£°ã§èª­ã¿ä¸Šã’ï¼ˆTTSãŒæœ‰åŠ¹ãªå ´åˆï¼‰
        if (result.response && isTTSEnabled) {
          speakText(result.response)
        }
      } else {
        addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: ${result.error}`)
        console.error("Chat error:", result.error)
      }
    } catch (error) {
      console.error("éŸ³å£°ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ éŸ³å£°ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`)
    } finally {
      setIsSendingChat(false)
    }
  }

  // ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
  const startScreenShare = async (): Promise<MediaStream> => {
    const mediaStream = await navigator.mediaDevices.getDisplayMedia({
      video: {
        width: { ideal: 1920 },
        height: { ideal: 1080 },
        frameRate: { ideal: 30 },
      },
      audio: false,
    })

    mediaStream.getVideoTracks()[0].addEventListener("ended", () => {
      addMessage("system", "ç”»é¢å…±æœ‰ãŒåœæ­¢ã•ã‚Œã¾ã—ãŸã€‚")
      stopCapture()
    })

    return mediaStream
  }

  // ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
  const startCamera = async (): Promise<MediaStream> => {
    const mediaStream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        frameRate: { ideal: 30 },
        facingMode: "user",
      },
      audio: false,
    })

    return mediaStream
  }

  // ãƒ¡ã‚¤ãƒ³ã®ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹é–¢æ•°
  const startCapture = async () => {
    try {
      let mediaStream: MediaStream

      if (captureMode === "screen") {
        if (!capabilities.screenShare) {
          throw new Error("ç”»é¢å…±æœ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        }

        try {
          mediaStream = await startScreenShare()
          addMessage("system", "âœ… ç”»é¢å…±æœ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
        } catch (error: any) {
          console.error("Screen share error:", error)

          if (error.name === "NotAllowedError") {
            addMessage("system", "âš ï¸ ç”»é¢å…±æœ‰ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚")

            if (capabilities.camera) {
              addMessage("system", "ğŸ’¡ ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦å†è©¦è¡Œã—ã¾ã™...")
              setCaptureMode("camera")
              mediaStream = await startCamera()
              addMessage("system", "âœ… ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã§é–‹å§‹ã—ã¾ã—ãŸã€‚")
            } else {
              throw new Error("ç”»é¢å…±æœ‰ãŒæ‹’å¦ã•ã‚Œã€ã‚«ãƒ¡ãƒ©ã‚‚åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            }
          } else if (error.name === "NotSupportedError") {
            throw new Error("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯ç”»é¢å…±æœ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
          } else if (error.name === "AbortError") {
            throw new Error("ç”»é¢å…±æœ‰ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚")
          } else {
            throw new Error(`ç”»é¢å…±æœ‰ã‚¨ãƒ©ãƒ¼: ${error.message}`)
          }
        }
      } else {
        if (!capabilities.camera) {
          throw new Error("ã‚«ãƒ¡ãƒ©ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        }

        try {
          mediaStream = await startCamera()
          addMessage("system", "âœ… ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚")
        } catch (error: any) {
          if (error.name === "NotAllowedError") {
            throw new Error("ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ã‚«ãƒ¡ãƒ©ã®è¨±å¯ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚")
          } else if (error.name === "NotFoundError") {
            throw new Error("ã‚«ãƒ¡ãƒ©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
          } else {
            throw new Error(`ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: ${error.message}`)
          }
        }
      }

      setStream(mediaStream)

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream
        await videoRef.current.play()
      }

      setIsCapturing(true)
      addMessage("system", `${frequency}ç§’é–“éš”ã§ç”»åƒè§£æã‚’é–‹å§‹ã—ã¾ã™ã€‚éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚`)

      // æœ€åˆã®ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å®Ÿè¡Œ
      setTimeout(() => captureAndAnalyze(), 2000)

      // å®šæœŸçš„ã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’å®Ÿè¡Œ
      intervalRef.current = setInterval(() => {
        captureAndAnalyze()
      }, Number.parseInt(frequency) * 1000)
    } catch (error) {
      console.error("ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ ${error instanceof Error ? error.message : "ã‚­ãƒ£ãƒ—ãƒãƒ£ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"}`)

      if (captureMode === "screen" && capabilities.camera) {
        addMessage("system", "ğŸ’¡ ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
      }
    }
  }

  const stopCapture = () => {
    stopCurrentAudio()

    if (intervalRef.current) {
      clearInterval(intervalRef.current)
      intervalRef.current = null
    }

    if (stream) {
      stream.getTracks().forEach((track) => track.stop())
      setStream(null)
    }

    if (videoRef.current) {
      videoRef.current.srcObject = null
    }

    setIsCapturing(false)
    addMessage("system", "ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")
  }

  const captureCurrentFrame = async (): Promise<string | null> => {
    if (!videoRef.current || !canvasRef.current) {
      return null
    }

    const canvas = canvasRef.current
    const ctx = canvas.getContext("2d")
    if (!ctx) return null

    if (videoRef.current.readyState < 2) {
      return null
    }

    canvas.width = videoRef.current.videoWidth
    canvas.height = videoRef.current.videoHeight

    if (canvas.width === 0 || canvas.height === 0) {
      return null
    }

    ctx.drawImage(videoRef.current, 0, 0)

    const imageDataUrl = canvas.toDataURL("image/jpeg", 0.9)
    const base64Data = imageDataUrl.split(",")[1]

    return base64Data
  }

  const captureAndAnalyze = async () => {
    if (!periodicPrompt.trim() || isProcessing) {
      return
    }

    setIsProcessing(true)

    try {
      const base64Data = await captureCurrentFrame()
      if (!base64Data) {
        throw new Error("ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã«å¤±æ•—ã—ã¾ã—ãŸ")
      }

      addMessage("system", "ğŸ” å®šæœŸè§£æä¸­...", true)

      const response = await fetch("/api/analyze-image", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          image: base64Data,
          prompt: periodicPrompt,
          mimeType: "image/jpeg",
        }),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", `[å®šæœŸè§£æ] ${result.analysis}`, true)

        if (result.analysis && isTTSEnabled) {
          speakText(result.analysis)
        }
      } else {
        addMessage("system", `âŒ å®šæœŸè§£æã‚¨ãƒ©ãƒ¼: ${result.error}`, true)
        console.error("Analysis error:", result.error)
      }
    } catch (error) {
      console.error("å®šæœŸè§£æã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ å®šæœŸè§£æã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`, true)
    } finally {
      setIsProcessing(false)
    }
  }

  const sendChatMessage = async () => {
    if (!chatMessage.trim() || isSendingChat) {
      return
    }

    const userMessage = chatMessage.trim()
    setChatMessage("")
    setIsSendingChat(true)

    try {
      addMessage("user", userMessage)

      const base64Data = await captureCurrentFrame()

      const requestBody: any = {
        prompt: userMessage,
        mimeType: "image/jpeg",
      }

      if (base64Data) {
        requestBody.image = base64Data
        addMessage("system", "ğŸ“¸ ç¾åœ¨ã®ç”»åƒã¨ä¸€ç·’ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
      } else {
        addMessage("system", "ğŸ’¬ ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ä¸­...")
      }

      const response = await fetch("/api/chat", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify(requestBody),
      })

      const result = await response.json()

      if (result.success) {
        addMessage("ai", result.response, false, false, !!base64Data)

        if (result.response && isTTSEnabled) {
          speakText(result.response)
        }
      } else {
        addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: ${result.error}`)
        console.error("Chat error:", result.error)
      }
    } catch (error) {
      console.error("ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼:", error)
      addMessage("system", `âŒ ãƒãƒ£ãƒƒãƒˆé€ä¿¡ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"}`)
    } finally {
      setIsSendingChat(false)
    }
  }

  const speakText = async (text: string) => {
    try {
      stopCurrentAudio()

      const response = await fetch("/api/text-to-speech", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
      })

      if (response.ok) {
        const audioBlob = await response.blob()
        const audioUrl = URL.createObjectURL(audioBlob)
        const audio = new Audio(audioUrl)

        currentAudioRef.current = audio

        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          currentAudioRef.current = null
        }

        audio.onerror = () => {
          URL.revokeObjectURL(audioUrl)
          currentAudioRef.current = null
        }

        await audio.play()
      } else {
        console.error("TTS API error:", await response.text())
      }
    } catch (error) {
      console.error("éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:", error)
    }
  }

  const toggleVoiceMode = () => {
    if (!recognitionRef.current) {
      addMessage("system", "âŒ éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
      return
    }

    if (isVoiceMode) {
      setIsVoiceMode(false)
      if (isListening) {
        recognitionRef.current.stop()
      }
      addMessage("system", "ğŸ”‡ éŸ³å£°ãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")
    } else {
      setIsVoiceMode(true)
      recognitionRef.current.start()
      addMessage(
        "system",
        "ğŸ¤ éŸ³å£°ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚ã€Œç”»é¢å…±æœ‰ã€ã€Œã‚«ãƒ¡ãƒ©ã€ã€Œåœæ­¢ã€ãªã©ã®éŸ³å£°ã‚³ãƒãƒ³ãƒ‰ãŒåˆ©ç”¨ã§ãã¾ã™ã€‚",
      )
    }
  }

  const toggleListening = () => {
    if (!recognitionRef.current) {
      addMessage("system", "âŒ éŸ³å£°èªè­˜ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
      return
    }

    if (isListening) {
      recognitionRef.current.stop()
    } else {
      recognitionRef.current.start()
    }
  }

  const manualCapture = () => {
    if (isCapturing && !isProcessing) {
      captureAndAnalyze()
    }
  }

  const handleChatKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault()
      sendChatMessage()
    }
  }

  const toggleTTS = () => {
    if (!isTTSEnabled) {
      setIsTTSEnabled(true)
      addMessage("system", "ğŸ”Š éŸ³å£°èª­ã¿ä¸Šã’ã‚’æœ‰åŠ¹ã«ã—ã¾ã—ãŸã€‚")
    } else {
      setIsTTSEnabled(false)
      stopCurrentAudio()
      addMessage("system", "ğŸ”‡ éŸ³å£°èª­ã¿ä¸Šã’ã‚’ç„¡åŠ¹ã«ã—ã¾ã—ãŸã€‚")
    }
  }

  const handleCaptureModeChange = (value: "camera" | "screen") => {
    if (value === "screen" && !capabilities.screenShare) {
      addMessage("system", "âš ï¸ ç”»é¢å…±æœ‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
      return
    }
    setCaptureMode(value)
  }

  return (
    <div className="min-h-screen bg-gray-50 p-4">
      <div className="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-3 gap-6">
        {/* å·¦å´: ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒ‘ãƒãƒ« */}
        <Card className="lg:col-span-1">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <Camera className="w-5 h-5" />
              AI Vision Chat
            </CardTitle>
          </CardHeader>
          <CardContent className="space-y-6">
            {/* APIçŠ¶æ…‹è¡¨ç¤º */}
            <Alert>
              <AlertCircle className="h-4 w-4" />
              <AlertDescription className="flex items-center gap-2">
                {apiStatus.gemini && apiStatus.tts ? (
                  <CheckCircle className="w-4 h-4 text-green-500" />
                ) : (
                  <AlertCircle className="w-4 h-4 text-yellow-500" />
                )}
                {apiStatus.message}
              </AlertDescription>
            </Alert>

            {/* éŸ³å£°ãƒ¢ãƒ¼ãƒ‰çŠ¶æ…‹ */}
            {capabilities.speechRecognition && (
              <Alert>
                <Headphones className="h-4 w-4" />
                <AlertDescription>
                  <div className="flex items-center justify-between">
                    <span className="text-sm">
                      éŸ³å£°ãƒ¢ãƒ¼ãƒ‰: {isVoiceMode ? "æœ‰åŠ¹" : "ç„¡åŠ¹"}
                      {isListening && " (èãå–ã‚Šä¸­...)"}
                    </span>
                    <Button variant={isVoiceMode ? "destructive" : "outline"} size="sm" onClick={toggleVoiceMode}>
                      {isVoiceMode ? <MicOff className="w-3 h-3" /> : <Mic className="w-3 h-3" />}
                    </Button>
                  </div>
                  {interimTranscript && (
                    <div className="mt-2 p-2 bg-blue-50 rounded text-xs">èªè­˜ä¸­: "{interimTranscript}"</div>
                  )}
                </AlertDescription>
              </Alert>
            )}

            {/* éŸ³å£°è¨­å®š */}
            {capabilities.speechRecognition && (
              <div>
                <Label className="text-base font-medium flex items-center gap-2">
                  <Settings className="w-4 h-4" />
                  éŸ³å£°è¨­å®š
                </Label>
                <Select value={voiceLanguage} onValueChange={setVoiceLanguage}>
                  <SelectTrigger className="mt-2">
                    <SelectValue />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="ja-JP">æ—¥æœ¬èª</SelectItem>
                    <SelectItem value="en-US">English (US)</SelectItem>
                    <SelectItem value="en-GB">English (UK)</SelectItem>
                    <SelectItem value="zh-CN">ä¸­æ–‡ (ç®€ä½“)</SelectItem>
                    <SelectItem value="ko-KR">í•œêµ­ì–´</SelectItem>
                  </SelectContent>
                </Select>
              </div>
            )}

            {/* æ©Ÿèƒ½ã‚µãƒãƒ¼ãƒˆçŠ¶æ³ */}
            <Alert>
              <Info className="h-4 w-4" />
              <AlertDescription>
                <div className="text-sm">
                  <div className="font-medium mb-2">æ©Ÿèƒ½çŠ¶æ³:</div>
                  <div className="space-y-1">
                    <div className="flex items-center gap-2">
                      <Camera className="w-3 h-3" />
                      <span className={capabilities.camera ? "text-green-600" : "text-red-600"}>
                        ã‚«ãƒ¡ãƒ©: {capabilities.camera ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                      </span>
                    </div>
                    <div className="flex items-center gap-2">
                      <Monitor className="w-3 h-3" />
                      <span className={capabilities.screenShare ? "text-green-600" : "text-red-600"}>
                        ç”»é¢å…±æœ‰: {capabilities.screenShare ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                      </span>
                    </div>
                    <div className="flex items-center gap-2">
                      <Mic className="w-3 h-3" />
                      <span className={capabilities.speechRecognition ? "text-green-600" : "text-red-600"}>
                        éŸ³å£°èªè­˜: {capabilities.speechRecognition ? "åˆ©ç”¨å¯èƒ½" : "åˆ©ç”¨ä¸å¯"}
                      </span>
                    </div>
                  </div>
                  {capabilities.speechRecognition && (
                    <div className="mt-2 p-2 bg-blue-50 rounded text-xs">
                      ğŸ’¡ éŸ³å£°ã‚³ãƒãƒ³ãƒ‰: ã€Œç”»é¢å…±æœ‰ã€ã€Œã‚«ãƒ¡ãƒ©ã€ã€Œåœæ­¢ã€ã€ŒéŸ³å£°ãƒ¢ãƒ¼ãƒ‰çµ‚äº†ã€
                    </div>
                  )}
                </div>
              </AlertDescription>
            </Alert>

            {/* ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰é¸æŠ */}
            <div>
              <Label className="text-base font-medium">ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰</Label>
              <RadioGroup
                value={captureMode}
                onValueChange={handleCaptureModeChange}
                className="flex gap-6 mt-2"
                disabled={isCapturing}
              >
                <div className="flex items-center space-x-2">
                  <RadioGroupItem value="camera" id="camera" disabled={!capabilities.camera} />
                  <Label
                    htmlFor="camera"
                    className={`flex items-center gap-2 ${!capabilities.camera ? "opacity-50" : ""}`}
                  >
                    <Camera className="w-4 h-4" />
                    ã‚«ãƒ¡ãƒ©
                  </Label>
                </div>
                <div className="flex items-center space-x-2">
                  <RadioGroupItem value="screen" id="screen" disabled={!capabilities.screenShare} />
                  <Label
                    htmlFor="screen"
                    className={`flex items-center gap-2 ${!capabilities.screenShare ? "opacity-50" : ""}`}
                  >
                    <Monitor className="w-4 h-4" />
                    ç”»é¢å…±æœ‰
                  </Label>
                </div>
              </RadioGroup>
            </div>

            {/* å®šæœŸè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ */}
            <div>
              <Label htmlFor="periodicPrompt" className="text-base font-medium flex items-center gap-2">
                <Eye className="w-4 h-4" />
                å®šæœŸè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
              </Label>
              <Textarea
                id="periodicPrompt"
                value={periodicPrompt}
                onChange={(e) => setPeriodicPrompt(e.target.value)}
                placeholder="å®šæœŸçš„ãªç”»åƒè§£æã§ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ..."
                className="mt-2 min-h-[80px]"
                disabled={isCapturing}
              />
            </div>

            {/* ã‚­ãƒ£ãƒ—ãƒãƒ£é »åº¦ */}
            <div>
              <Label className="text-base font-medium">ã‚­ãƒ£ãƒ—ãƒãƒ£é »åº¦</Label>
              <Select value={frequency} onValueChange={setFrequency} disabled={isCapturing}>
                <SelectTrigger className="mt-2">
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="10">10ç§’</SelectItem>
                  <SelectItem value="20">20ç§’</SelectItem>
                  <SelectItem value="30">30ç§’</SelectItem>
                </SelectContent>
              </Select>
            </div>

            {/* ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³ */}
            <div className="space-y-2">
              <div className="flex gap-2">
                <Button
                  onClick={isCapturing ? stopCapture : startCapture}
                  disabled={
                    !periodicPrompt.trim() ||
                    !apiStatus.gemini ||
                    !apiStatus.tts ||
                    (!capabilities.camera && !capabilities.screenShare)
                  }
                  className="flex-1"
                  size="lg"
                >
                  {isCapturing ? (
                    <>
                      <Square className="w-4 h-4 mr-2" />
                      åœæ­¢
                    </>
                  ) : (
                    <>
                      <Play className="w-4 h-4 mr-2" />
                      é–‹å§‹
                    </>
                  )}
                </Button>

                <Button onClick={toggleTTS} variant="outline" size="lg">
                  {isTTSEnabled ? <Volume2 className="w-4 h-4" /> : <VolumeX className="w-4 h-4" />}
                </Button>
              </div>

              {isCapturing && (
                <Button onClick={manualCapture} disabled={isProcessing} variant="outline" className="w-full">
                  {isProcessing ? "å‡¦ç†ä¸­..." : "ä»Šã™ãè§£æ"}
                </Button>
              )}
            </div>

            {/* ãƒ“ãƒ‡ã‚ªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */}
            <div className="relative">
              <video
                ref={videoRef}
                className="w-full rounded-lg bg-black"
                style={{ maxHeight: "200px" }}
                muted
                playsInline
              />
              <canvas ref={canvasRef} className="hidden" />
              {isProcessing && (
                <div className="absolute inset-0 bg-black bg-opacity-50 flex items-center justify-center rounded-lg">
                  <div className="text-white text-sm">è§£æä¸­...</div>
                </div>
              )}
              {isCapturing && (
                <div className="absolute top-2 left-2 bg-red-500 text-white px-2 py-1 rounded text-xs">
                  {captureMode === "screen" ? "ç”»é¢å…±æœ‰ä¸­" : "ã‚«ãƒ¡ãƒ©æ’®å½±ä¸­"}
                </div>
              )}
              {isVoiceMode && (
                <div className="absolute top-2 right-2 bg-blue-500 text-white px-2 py-1 rounded text-xs flex items-center gap-1">
                  <Mic className="w-3 h-3" />
                  éŸ³å£°ãƒ¢ãƒ¼ãƒ‰
                </div>
              )}
            </div>
          </CardContent>
        </Card>

        {/* å³å´: ãƒãƒ£ãƒƒãƒˆç”»é¢ */}
        <Card className="lg:col-span-2">
          <CardHeader>
            <CardTitle className="flex items-center gap-2">
              <MessageSquare className="w-5 h-5" />
              ãƒãƒ£ãƒƒãƒˆå±¥æ­´
            </CardTitle>
          </CardHeader>
          <CardContent className="flex flex-col h-[600px]">
            {/* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã‚¨ãƒªã‚¢ */}
            <ScrollArea className="flex-1 pr-4 mb-4">
              <div className="space-y-4">
                {messages.map((message) => (
                  <div
                    key={message.id}
                    className={`flex ${message.type === "user" || message.type === "voice" ? "justify-end" : "justify-start"}`}
                  >
                    <div
                      className={`max-w-[80%] p-3 rounded-lg ${
                        message.type === "user"
                          ? "bg-blue-500 text-white"
                          : message.type === "voice"
                            ? "bg-purple-500 text-white"
                            : message.type === "system"
                              ? "bg-gray-100 text-gray-700 border"
                              : message.isPeriodicAnalysis
                                ? "bg-purple-100 text-purple-800 border border-purple-200"
                                : "bg-green-100 text-green-800"
                      }`}
                    >
                      <p className="text-sm whitespace-pre-wrap">{message.content}</p>
                      <div className="flex items-center justify-between mt-1">
                        <p className="text-xs opacity-70">{message.timestamp.toLocaleTimeString()}</p>
                        <div className="flex items-center gap-1">
                          {message.isVoiceInput && (
                            <span className="text-xs bg-purple-200 text-purple-700 px-2 py-1 rounded">éŸ³å£°å…¥åŠ›</span>
                          )}
                          {message.isPeriodicAnalysis && (
                            <span className="text-xs bg-purple-200 text-purple-700 px-2 py-1 rounded">å®šæœŸè§£æ</span>
                          )}
                          {message.hasImage && (
                            <span className="text-xs bg-blue-200 text-blue-700 px-2 py-1 rounded">ç”»åƒä»˜ã</span>
                          )}
                        </div>
                      </div>
                    </div>
                  </div>
                ))}
                <div ref={messagesEndRef} />
              </div>
            </ScrollArea>

            {/* ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ */}
            <div className="border-t pt-4">
              <Label htmlFor="chatMessage" className="text-sm font-medium flex items-center gap-2 mb-2">
                <MessageSquare className="w-4 h-4" />
                ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆ
              </Label>
              <div className="flex gap-2">
                <Textarea
                  id="chatMessage"
                  value={chatMessage}
                  onChange={(e) => setChatMessage(e.target.value)}
                  onKeyPress={handleChatKeyPress}
                  placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„... (Enterã§é€ä¿¡ã€Shift+Enterã§æ”¹è¡Œ)"
                  className="flex-1 min-h-[60px] max-h-[120px]"
                  disabled={isSendingChat}
                />
                <div className="flex flex-col gap-2">
                  <Button
                    onClick={sendChatMessage}
                    disabled={!chatMessage.trim() || isSendingChat || !apiStatus.gemini}
                    size="sm"
                  >
                    {isSendingChat ? (
                      "é€ä¿¡ä¸­..."
                    ) : (
                      <>
                        <Send className="w-4 h-4" />
                      </>
                    )}
                  </Button>
                  <Button
                    variant={isListening ? "destructive" : "outline"}
                    size="sm"
                    onClick={toggleListening}
                    disabled={!capabilities.speechRecognition}
                  >
                    {isListening ? <MicOff className="w-4 h-4" /> : <Mic className="w-4 h-4" />}
                  </Button>
                </div>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>
    </div>
  )
}
